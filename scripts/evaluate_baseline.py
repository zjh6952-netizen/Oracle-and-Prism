import os
import pandas as pd
import torch
import evaluate 
from tqdm import tqdm
from transformers import T5Tokenizer, T5ForConditionalGeneration

# ==============================================================================
# 1. é…ç½®éƒ¨åˆ† (CONFIGURATION)
# ==============================================================================

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
PROJECT_ROOT = "/root/autodl-tmp/GenRec_Explainer_Project"

BASELINE_MODEL_PATH = os.path.join(PROJECT_ROOT, "models", "flan-t5-xxl")

# --- ã€æ ¸å¿ƒã€‘BERTScoreä¾èµ–çš„robertaæ¨¡å‹çš„æœ¬åœ°è·¯å¾„ ---
#ROBERTA_LOCAL_PATH = os.path.join(PROJECT_ROOT, "models", "roberta-large")

# --- è¯„ä¼°è„šæœ¬çš„æœ¬åœ°è·¯å¾„ ---
METRICS_DIR = os.path.join(PROJECT_ROOT, "offline_metrics")
ROUGE_SCRIPT_PATH = os.path.join(METRICS_DIR, "rouge")
#BERTSCORE_SCRIPT_PATH = os.path.join(METRICS_DIR, "bertscore")

# --- æ•°æ®å’Œç»“æœè·¯å¾„ ---
TEST_DATA_PATH = os.path.join(PROJECT_ROOT, "data", "processed", "explanation_dataset_test.csv")
RESULTS_PATH = os.path.join(PROJECT_ROOT, "results", "evaluation_results_baseline.csv")

# ==============================================================================
# 2. æ¨¡å‹åŠ è½½ä¸ç”Ÿæˆå‡½æ•°
# ==============================================================================

def load_teacher_t5_model(model_path):
    """ä¸“é—¨ä»¥é«˜æ€§èƒ½æ¨¡å¼åŠ è½½FLAN-T5æ•™å¸ˆæ¨¡å‹ä½œä¸ºåŸºçº¿"""
    print(f"--- æ­£åœ¨åŠ è½½åŸºçº¿æ¨¡å‹ (FLAN-T5-XXL) ---")
    print(f"  - è·¯å¾„: {model_path}")
    try:
        tokenizer = T5Tokenizer.from_pretrained(model_path, local_files_only=True)
        model = T5ForConditionalGeneration.from_pretrained(
            model_path,
            torch_dtype=torch.bfloat16,
            device_map={"": 0},
            local_files_only=True
        )
        model.eval()
        print("åŸºçº¿æ¨¡å‹åŠ è½½æˆåŠŸã€‚")
        return model, tokenizer
    except Exception as e:
        print(f"!!! åŠ è½½åŸºçº¿æ¨¡å‹å¤±è´¥: {e}"); return None, None

def generate_explanation(model, tokenizer, history, item):
    """ä¸ºæ¨¡å‹ç”Ÿæˆè§£é‡Š"""
    # --- ã€æ ¸å¿ƒä¿®æ”¹ã€‘ä½¿ç”¨Yelpç‰ˆçš„Prompt ---
    prompt = f"Instruction: Generate a short and faithful explanation for the following local business recommendation.\nInput: User Visit History: {history}\nRecommended Business: {item}"
    
    inputs = tokenizer(prompt, return_tensors="pt", max_length=512, truncation=True).to(model.device)
    outputs = model.generate(**inputs, max_new_tokens=150, num_beams=5)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)
# ==============================================================================
# 3. ä¸»ç¨‹åº (MAIN LOGIC)
# ==============================================================================

def main():
    baseline_model, baseline_tokenizer = load_teacher_t5_model(BASELINE_MODEL_PATH)
    if not baseline_model:
        return

    print("\n--- æ­£åœ¨ä»æœ¬åœ°åŠ è½½è¯„ä¼°æŒ‡æ ‡ ---")
    try:
        rouge = evaluate.load(ROUGE_SCRIPT_PATH)
        #bertscore = evaluate.load(BERTSCORE_SCRIPT_PATH)
        print("è¯„ä¼°æŒ‡æ ‡åŠ è½½æˆåŠŸã€‚")
    except Exception as e:
        print(f"!!! åŠ è½½ç¦»çº¿è¯„ä¼°æŒ‡æ ‡å¤±è´¥: {e}")
        return
        
    print(f"\n--- æ­£åœ¨åŠ è½½æµ‹è¯•æ•°æ® ---")
    try:
        df = pd.read_csv(TEST_DATA_PATH)
        # æ­£å¼è¯„ä¼°ï¼Œå¤„ç†å…¨éƒ¨æ•°æ®
        #df = df.head(1000)
    except FileNotFoundError:
        print(f"!!! é”™è¯¯: æµ‹è¯•é›†æ–‡ä»¶æœªæ‰¾åˆ°! '{TEST_DATA_PATH}'")
        return

    results = []
    print(f"\n--- æ­£åœ¨ä¸ºåŸºçº¿æ¨¡å‹ (FLAN-T5-XXL) ç”Ÿæˆ {len(df)} æ¡è§£é‡Š ---")
    for index, row in tqdm(df.iterrows(), total=len(df)):
        history, item, reference = str(row['history']), str(row['recommended_item']), str(row['explanation'])
        baseline_pred = generate_explanation(baseline_model, baseline_tokenizer, history, item)
        results.append({'golden': reference, 'prediction': baseline_pred})
        
    results_df = pd.DataFrame(results)
    references = results_df['golden'].tolist()
    predictions = results_df['prediction'].tolist()
    
    print("\n--- æ­£åœ¨è®¡ç®—è‡ªåŠ¨åŒ–è¯„ä¼°æŒ‡æ ‡ ---")
    rouge_scores = rouge.compute(predictions=predictions, references=references)
    
    # --- ã€æ ¸å¿ƒä¿®å¤ã€‘åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æ˜ç¡®åœ°å‘Šè¯‰bertscoreå»å“ªé‡Œæ‰¾roberta-large ---
    #print("æ­£åœ¨è®¡ç®—BERTScore (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...")
   # bert_scores = bertscore.compute(
        #predictions=predictions, 
        #references=references, 
        #lang="en",
        #model_type="roberta-large"
    #)
    #bert_f1 = sum(bert_scores['f1'])/len(bert_scores['f1']) if bert_scores['f1'] else 0.0

    print("\n--- åŸºçº¿æ¨¡å‹ (FLAN-T5-XXL) è¯„ä¼°ç»“æœ ---")
    print(f"{'Metric':<15} | {'Score':<10}")
    print("-" * 30)
    print(f"{'ROUGE-1':<15} | {rouge_scores.get('rouge1', 0.0):.4f}")
    print(f"{'ROUGE-2':<15} | {rouge_scores.get('rouge2', 0.0):.4f}")
    print(f"{'ROUGE-L':<15} | {rouge_scores.get('rougeL', 0.0):.4f}")
    #print(f"{'BERTScore-F1':<15} | {bert_f1:.4f}")

    results_df.to_csv(RESULTS_PATH, index=False)
    print(f"\nè¯¦ç»†ç”Ÿæˆç»“æœå·²ä¿å­˜åˆ°: {RESULTS_PATH}")
    print("\nğŸ‰ åŸºçº¿æ¨¡å‹è¯„ä¼°å®Œæˆï¼")

if __name__ == "__main__":
    main()