import os
import pandas as pd
import torch
import evaluate 
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# ==============================================================================
# 1. é…ç½®éƒ¨åˆ† (CONFIGURATION)
# ==============================================================================

# ã€ä¿®å¤ã€‘æ˜ç¡®è®¾å¤‡é€‰æ‹©ï¼Œæ”¯æŒCPUæ¨¡å¼
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ä½¿ç”¨è®¾å¤‡: {DEVICE}")
PROJECT_ROOT = "/root/autodl-tmp/GenRec_Explainer_Project"

# --- ã€æ ¸å¿ƒã€‘æ¨¡å‹è·¯å¾„æŒ‡å‘åŸå§‹çš„ã€æœªç»å¾®è°ƒçš„BART-Base (æœ€å†…å±‚) ---
BART_BASELINE_PATH = os.path.join(PROJECT_ROOT, "models", "bart-base", "facebook", "bart-base")

# --- BERTScoreä¾èµ–çš„robertaæ¨¡å‹çš„æœ¬åœ°è·¯å¾„ ---
#ROBERTA_LOCAL_PATH = os.path.join(PROJECT_ROOT, "models", "roberta-large")

# --- è¯„ä¼°è„šæœ¬çš„æœ¬åœ°è·¯å¾„ ---
METRICS_DIR = os.path.join(PROJECT_ROOT, "offline_metrics")
ROUGE_SCRIPT_PATH = os.path.join(METRICS_DIR, "rouge")
#BERTSCORE_SCRIPT_PATH = os.path.join(METRICS_DIR, "bertscore")

# --- æ•°æ®å’Œç»“æœè·¯å¾„ ---
TEST_DATA_PATH = os.path.join(PROJECT_ROOT, "data", "processed", "explanation_dataset_test.csv")
RESULTS_PATH = os.path.join(PROJECT_ROOT, "results", "evaluation_results_bart_baseline.csv")

# ==============================================================================
# 2. æ¨¡å‹åŠ è½½ä¸ç”Ÿæˆå‡½æ•°
# ==============================================================================

def load_bart_baseline(model_path):
    """ä¸“é—¨åŠ è½½åŸå§‹çš„ã€æœªç»å¾®è°ƒçš„BART-Baseæ¨¡å‹"""
    print(f"--- æ­£åœ¨åŠ è½½BART-Base (Zero-Shot)åŸºçº¿æ¨¡å‹ ---")
    print(f"  - è·¯å¾„: {model_path}")
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)
        model = AutoModelForSeq2SeqLM.from_pretrained(model_path, local_files_only=True)
        model = model.to(DEVICE)
        model.eval()
        print("BART-BaseåŸºçº¿æ¨¡å‹åŠ è½½æˆåŠŸã€‚")
        return model, tokenizer
    except Exception as e:
        print(f"!!! åŠ è½½BART-BaseåŸºçº¿å¤±è´¥: {e}")
        return None, None

def generate_explanation(model, tokenizer, history, item):
    """ä¸ºæ¨¡å‹ç”Ÿæˆè§£é‡Šï¼Œä½¿ç”¨ä¸è®­ç»ƒæ—¶ä¸€è‡´çš„Promptæ ¼å¼"""
    # ã€ä¿®å¤ã€‘ä½¿ç”¨ç®€åŒ–æ ¼å¼
    prompt = f"User History: {history}\nRecommended Item: {item}\nExplanation:"
    inputs = tokenizer(prompt, return_tensors="pt", max_length=768, truncation=True).to(model.device)
    outputs = model.generate(**inputs, max_new_tokens=150, num_beams=5)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# ==============================================================================
# 3. ä¸»ç¨‹åº (MAIN LOGIC)
# ==============================================================================

def main():
    bart_baseline_model, bart_baseline_tokenizer = load_bart_baseline(BART_BASELINE_PATH)
    if not bart_baseline_model:
        return
        
    print("\n--- æ­£åœ¨ä»æœ¬åœ°åŠ è½½è¯„ä¼°æŒ‡æ ‡ ---")
    try:
        rouge = evaluate.load(ROUGE_SCRIPT_PATH)
        #bertscore = evaluate.load(BERTSCORE_SCRIPT_PATH)
        print("è¯„ä¼°æŒ‡æ ‡åŠ è½½æˆåŠŸã€‚")
    except Exception as e:
        print(f"!!! åŠ è½½ç¦»çº¿è¯„ä¼°æŒ‡æ ‡å¤±è´¥: {e}")
        return
    
    print(f"\n--- æ­£åœ¨åŠ è½½æµ‹è¯•æ•°æ® ---")
    try:
        df = pd.read_csv(TEST_DATA_PATH)
        # æ­£å¼è¯„ä¼°ï¼Œå¤„ç†å…¨éƒ¨æ•°æ®
        df = df.head(5000) 
    except FileNotFoundError:
        print(f"!!! é”™è¯¯: æµ‹è¯•é›†æ–‡ä»¶æœªæ‰¾åˆ°! '{TEST_DATA_PATH}'")
        return

    results = []
    print(f"\n--- æ­£åœ¨ä¸ºBART-Base (Zero-Shot)åŸºçº¿ç”Ÿæˆ {len(df)} æ¡è§£é‡Š ---")
    for index, row in tqdm(df.iterrows(), total=len(df)):
        history, item, reference = str(row['history']), str(row['recommended_item']), str(row['explanation'])
        bart_pred = generate_explanation(bart_baseline_model, bart_baseline_tokenizer, history, item)
        results.append({
            'golden_explanation': reference,
            'prediction': bart_pred
        })

    results_df = pd.DataFrame(results)
    references = results_df['golden_explanation'].tolist()
    predictions = results_df['prediction'].tolist()
    
    print("\n--- æ­£åœ¨è®¡ç®—è‡ªåŠ¨åŒ–è¯„ä¼°æŒ‡æ ‡ ---")
    rouge_scores = rouge.compute(predictions=predictions, references=references)
    
    # --- ã€æ ¸å¿ƒä¿®å¤ã€‘åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æ˜ç¡®åœ°å‘Šè¯‰bertscoreå»å“ªé‡Œæ‰¾roberta-large ---
    #print("æ­£åœ¨è®¡ç®—BERTScore (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...")
    #bert_scores = bertscore.compute(
        #predictions=predictions, 
        #references=references, 
        #lang="en",
        #model_type="roberta-large"
    #)
    #bert_f1 = sum(bert_scores['f1'])/len(bert_scores['f1']) if bert_scores['f1'] else 0.0

    print("\n--- BART-Base (Zero-Shot)åŸºçº¿è¯„ä¼°ç»“æœ ---")
    print(f"{'Metric':<15} | {'Score':<10}")
    print("-" * 30)
    print(f"{'ROUGE-1':<15} | {rouge_scores.get('rouge1', 0.0):.4f}")
    print(f"{'ROUGE-2':<15} | {rouge_scores.get('rouge2', 0.0):.4f}")
    print(f"{'ROUGE-L':<15} | {rouge_scores.get('rougeL', 0.0):.4f}")
    #print(f"{'BERTScore-F1':<15} | {bert_f1:.4f}")
    
    results_df.to_csv(RESULTS_PATH, index=False)
    print(f"\nè¯¦ç»†ç”Ÿæˆç»“æœå·²ä¿å­˜åˆ°: {RESULTS_PATH}")
    print("\nğŸ‰ BART-BaseåŸºçº¿è¯„ä¼°å®Œæˆï¼")

if __name__ == "__main__":
    main()