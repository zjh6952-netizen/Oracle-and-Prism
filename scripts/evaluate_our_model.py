import os
import traceback
import pandas as pd
import torch
import evaluate 
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM # æ³¨æ„è¿™é‡ŒåŠ äº†AutoModel
# ã€æ ¸å¿ƒã€‘æˆ‘ä»¬ç›´æ¥å¯¼å…¥bert_scoreçš„æ ¸å¿ƒå·¥å…·ï¼Œä¸å†ä¾èµ–evaluateåº“æ¥åŠ è½½å®ƒ
#from bert_score import BERTScorer

# ==============================================================================
# 1. é…ç½®éƒ¨åˆ† (CONFIGURATION)
# ==============================================================================

# ã€ä¿®å¤ã€‘æ˜ç¡®è®¾å¤‡é€‰æ‹©ï¼Œæ”¯æŒCPUæ¨¡å¼
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ä½¿ç”¨è®¾å¤‡: {DEVICE}")
PROJECT_ROOT = "/root/autodl-tmp/GenRec_Explainer_Project"

# !! å…³é”® !!: è¯·å°† 'YYYYMMDD_HHMMSS' æ›¿æ¢ä¸ºä½ çœŸå®çš„è®­ç»ƒè¾“å‡ºæ–‡ä»¶å¤¹çš„æ—¶é—´æˆ³
YOUR_MODEL_WEIGHTS_PATH = os.path.join(PROJECT_ROOT, "results", "20250918_165141", "best_model.mdl") 

# å­¦ç”Ÿæ¨¡å‹çš„åŸºç¡€ç»“æ„è·¯å¾„ (æŒ‡å‘æœ€å†…å±‚)
YOUR_MODEL_BASE_PATH = os.path.join(PROJECT_ROOT, "models", "bart-base", "facebook", "bart-base")

# BERTScoreä¾èµ–çš„robertaæ¨¡å‹çš„æœ¬åœ°è·¯å¾„
ROBERTA_LOCAL_PATH = os.path.join(PROJECT_ROOT, "models", "roberta-large")

# è¯„ä¼°è„šæœ¬çš„æœ¬åœ°è·¯å¾„
METRICS_DIR = os.path.join(PROJECT_ROOT, "offline_metrics")
ROUGE_SCRIPT_PATH = os.path.join(METRICS_DIR, "rouge")
BERTSCORE_SCRIPT_PATH = os.path.join(METRICS_DIR, "bertscore")

# æ•°æ®å’Œç»“æœè·¯å¾„
TEST_DATA_PATH = os.path.join(PROJECT_ROOT, "data", "processed", "explanation_dataset_test.csv")
RESULTS_PATH = os.path.join(PROJECT_ROOT, "results", "evaluation_results_our_model.csv")
HUMAN_EVAL_PATH = os.path.join(PROJECT_ROOT, "results", "human_evaluation_data_for_our_model.csv")

# ç§»é™¤è¿™è¡Œï¼Œå› ä¸ºæˆ‘ä»¬ä¸å†ä¾èµ–HF_HOMEæ¥è¯†åˆ«bert_scoreçš„æ¨¡å‹è·¯å¾„
# os.environ['HF_HOME'] = os.path.join(PROJECT_ROOT, "models") 
# transformers_offline=1 ä»å¯ä¿ç•™ï¼Œä»¥é˜²æ­¢æ„å¤–çš„ç½‘ç»œè¯·æ±‚ï¼Œä½†åœ¨è¿™é‡Œå¹¶éå¿…éœ€ï¼Œå› ä¸ºæˆ‘ä»¬å°†ç›´æ¥ä¼ å…¥æ¨¡å‹
# os.environ['TRANSFORMERS_OFFLINE'] = "1" 

# ==============================================================================
# 2. æ¨¡å‹åŠ è½½ä¸ç”Ÿæˆå‡½æ•°
# ==============================================================================

def load_your_bart_model(base_path, weights_path):
    """ä¸“é—¨åŠ è½½æˆ‘ä»¬å¾®è°ƒå¥½çš„BARTå­¦ç”Ÿæ¨¡å‹"""
    print(f"--- æ­£åœ¨åŠ è½½ä½ å¾®è°ƒå¥½çš„BARTæ¨¡å‹ ---")
    print(f"  - åŸºç¡€ç»“æ„: {base_path}")
    print(f"  - å¾®è°ƒæƒé‡: {weights_path}")
    try:
        tokenizer = AutoTokenizer.from_pretrained(base_path, local_files_only=True)
        model = AutoModelForSeq2SeqLM.from_pretrained(base_path, local_files_only=True)
        model.load_state_dict(torch.load(weights_path, map_location=DEVICE), strict=False)
        model = model.to(DEVICE)
        model.eval()
        print("ä½ çš„æ¨¡å‹(GenRec-E)åŠ è½½æˆåŠŸã€‚")
        return model, tokenizer
    except Exception as e:
        print(f"!!! åŠ è½½ä½ çš„æ¨¡å‹å¤±è´¥! è¯·ç¡®ä¿è·¯å¾„æ­£ç¡®ä¸”è®­ç»ƒå·²å®Œæˆã€‚"); print(f"é”™è¯¯: {e}"); return None, None

def generate_explanation(model, tokenizer, history, item):
    """ä¸ºæ¨¡å‹ç”Ÿæˆè§£é‡Š"""
    # ã€ä¿®å¤ã€‘ä½¿ç”¨ä¸è®­ç»ƒæ—¶ä¸€è‡´çš„ç®€åŒ–æ ¼å¼
    prompt = f"User History: {history}\nRecommended Item: {item}\nExplanation:"
    inputs = tokenizer(prompt, return_tensors="pt", max_length=768, truncation=True).to(model.device)
    outputs = model.generate(**inputs, max_new_tokens=150, num_beams=5)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# ==============================================================================
# 3. ä¸»ç¨‹åº (MAIN LOGIC)
# ==============================================================================

def main():
    your_model, your_tokenizer = load_your_bart_model(YOUR_MODEL_BASE_PATH, YOUR_MODEL_WEIGHTS_PATH)
    if not your_model: 
        return
        
    print("\n--- æ­£åœ¨ä»æœ¬åœ°åŠ è½½è¯„ä¼°æŒ‡æ ‡ ---")
    try:
        rouge = evaluate.load(ROUGE_SCRIPT_PATH)
        print("âœ“ ROUGEè¯„ä¼°æŒ‡æ ‡åŠ è½½æˆåŠŸã€‚")
    except Exception as e:
        print(f"!!! åŠ è½½ROUGEå¤±è´¥: {e}"); return
    
    try:
        bertscore = evaluate.load(BERTSCORE_SCRIPT_PATH)
        print("âœ“ BERTScoreè¯„ä¼°æŒ‡æ ‡åŠ è½½æˆåŠŸã€‚")
    except Exception as e:
        print(f"!!! åŠ è½½BERTScoreå¤±è´¥: {e}")
        print("å°†ä»…ä½¿ç”¨ROUGEè¿›è¡Œè¯„ä¼°")
        bertscore = None

    # --- æ ¸å¿ƒä¿®å¤ï¼šç›´æ¥åŠ è½½roberta-largeæ¨¡å‹å’Œåˆ†è¯å™¨ï¼Œç„¶åä¼ ç»™BERTScorer ---
    #print("æ­£åœ¨é¢„åŠ è½½BERTScoreæ‰€éœ€çš„roberta-largeæ¨¡å‹å’Œåˆ†è¯å™¨...")
    #roberta_tokenizer = None
    #roberta_model = None
    #try:
        # ç›´æ¥ä½¿ç”¨ä½ çš„æœ¬åœ°è·¯å¾„åŠ è½½tokenizer
       # roberta_tokenizer = AutoTokenizer.from_pretrained(ROBERTA_LOCAL_PATH, local_files_only=True)
        # ç›´æ¥ä½¿ç”¨ä½ çš„æœ¬åœ°è·¯å¾„åŠ è½½model
        #roberta_model = AutoModel.from_pretrained(ROBERTA_LOCAL_PATH, local_files_only=True)
        #print("roberta-largeæ¨¡å‹å’Œåˆ†è¯å™¨é¢„åŠ è½½æˆåŠŸã€‚")
    #except Exception as e:
        #print(f"!!! é¢„åŠ è½½roberta-largeæ¨¡å‹æˆ–åˆ†è¯å™¨å¤±è´¥: {e}")
        #traceback.print_exc()
        #return

    #print("æ­£åœ¨åˆå§‹åŒ–BERTScorer (å°†ä½¿ç”¨é¢„åŠ è½½çš„roberta-large)...")
    #try:
        # å°†å·²åŠ è½½çš„tokenizerå’Œmodelç›´æ¥ä¼ é€’ç»™BERTScorer
        # æ³¨æ„ï¼šè¿™é‡Œä¸å†éœ€è¦model_typeå‚æ•°ï¼Œå› ä¸ºå®ƒä¼šè¢«modelå’Œtokenizerå‚æ•°è¦†ç›–
        #scorer = BERTScorer(model=roberta_model, tokenizer=roberta_tokenizer, lang="en", rescale_with_baseline=True, device=DEVICE)
        #print("BERTScoreråˆå§‹åŒ–æˆåŠŸã€‚")
    #except Exception as e:
       # print(f"!!! åˆå§‹åŒ–BERTScorerå¤±è´¥: {e}")
       # traceback.print_exc() 
        #return
    
    # ... (å…¶ä½™ä»£ç ä¿æŒä¸å˜) ...

    print(f"\n--- æ­£åœ¨åŠ è½½æµ‹è¯•æ•°æ® ---")
    try:
        df = pd.read_csv(TEST_DATA_PATH)
        # ã€å¿«é€Ÿæµ‹è¯•ã€‘åªè¯„ä¼°100æ¡è¿›è¡ŒBERTScoreå¿«é€Ÿæµ‹è¯•
        df = df.head(100)
        print(f"åŠ è½½äº† {len(df)} æ¡æµ‹è¯•æ•°æ®")
    except FileNotFoundError:
        print(f"!!! é”™è¯¯: æµ‹è¯•é›†æ–‡ä»¶æœªæ‰¾åˆ°! '{TEST_DATA_PATH}'"); return

    results = []
    print(f"\n--- æ­£åœ¨ä¸ºä½ çš„æ¨¡å‹ (GenRec-E) ç”Ÿæˆ {len(df)} æ¡è§£é‡Š ---")
    for index, row in tqdm(df.iterrows(), total=len(df)):
        history, item, reference = str(row['history']), str(row['recommended_item']), str(row['explanation'])
        your_pred = generate_explanation(your_model, your_tokenizer, history, item)
        results.append({ 
            'history': history, 'item': item,
            'golden': reference, 'prediction': your_pred
        })
        
    results_df = pd.DataFrame(results)
    references = results_df['golden'].tolist()
    predictions = results_df['prediction'].tolist()
    
    print("\n--- æ­£åœ¨è®¡ç®—è‡ªåŠ¨åŒ–è¯„ä¼°æŒ‡æ ‡ ---")
    print("æ­£åœ¨è®¡ç®—ROUGE...")
    rouge_scores = rouge.compute(predictions=predictions, references=references)
    
    bert_scores = None
    if bertscore:
        print("æ­£åœ¨è®¡ç®—BERTScore (å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…)...")
        try:
            bert_scores = bertscore.compute(
                predictions=predictions, 
                references=references, 
                lang="en",
                device=DEVICE
            )
            print("âœ“ BERTScoreè®¡ç®—å®Œæˆ")
        except Exception as e:
            print(f"!!! BERTScoreè®¡ç®—å¤±è´¥: {e}")
            bert_scores = None

    print("\n--- ä½ çš„æ¨¡å‹ (GenRec-E) è¯„ä¼°ç»“æœ ---")
    print(f"{'Metric':<15} | {'Score':<10}")
    print("-" * 30)
    print(f"{'ROUGE-1':<15} | {rouge_scores.get('rouge1', 0.0):.4f}")
    print(f"{'ROUGE-2':<15} | {rouge_scores.get('rouge2', 0.0):.4f}")
    print(f"{'ROUGE-L':<15} | {rouge_scores.get('rougeL', 0.0):.4f}")
    if bert_scores:
        bert_f1 = sum(bert_scores['f1']) / len(bert_scores['f1'])
        print(f"{'BERTScore-F1':<15} | {bert_f1:.4f}")
    
    results_df.to_csv(RESULTS_PATH, index=False)
    results_df.to_csv(HUMAN_EVAL_PATH, index=False)
    print(f"\nè¯¦ç»†ç”Ÿæˆç»“æœå·²ä¿å­˜åˆ°: {RESULTS_PATH}")
    print("\nğŸ‰ ä½ çš„æ¨¡å‹è¯„ä¼°å®Œæˆï¼")

if __name__ == "__main__":
    main()