import os
import pandas as pd
import torch
import evaluate 
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
# ã€æ ¸å¿ƒã€‘æˆ‘ä»¬ç›´æ¥å¯¼å…¥bert_scoreçš„æ ¸å¿ƒå·¥å…·ï¼Œä¸å†ä¾èµ–evaluateåº“æ¥åŠ è½½å®ƒ
from bert_score import BERTScorer

# ==============================================================================
# 1. é…ç½®éƒ¨åˆ† (CONFIGURATION)
# ==============================================================================

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
PROJECT_ROOT = "/root/autodl-tmp/GenRec_Explainer_Project"

# !! å…³é”® !!: è¯·å°† 'YYYYMMDD_HHMMSS' æ›¿æ¢ä¸ºä½ çœŸå®çš„è®­ç»ƒè¾“å‡ºæ–‡ä»¶å¤¹çš„æ—¶é—´æˆ³
YOUR_MODEL_WEIGHTS_PATH = os.path.join(PROJECT_ROOT, "results", "20250905_163846", "best_model.mdl") 

# å­¦ç”Ÿæ¨¡å‹çš„åŸºç¡€ç»“æ„è·¯å¾„ (æŒ‡å‘æœ€å†…å±‚)
YOUR_MODEL_BASE_PATH = os.path.join(PROJECT_ROOT, "models", "bart-base", "facebook", "bart-base")

# BERTScoreä¾èµ–çš„robertaæ¨¡å‹çš„æœ¬åœ°è·¯å¾„
ROBERTA_LOCAL_PATH = os.path.join(PROJECT_ROOT, "models", "roberta-large")

# è¯„ä¼°è„šæœ¬çš„æœ¬åœ°è·¯å¾„
METRICS_DIR = os.path.join(PROJECT_ROOT, "offline_metrics")
ROUGE_SCRIPT_PATH = os.path.join(METRICS_DIR, "rouge")

# æ•°æ®å’Œç»“æœè·¯å¾„
TEST_DATA_PATH = os.path.join(PROJECT_ROOT, "data", "processed", "explanation_dataset_test.csv")
RESULTS_PATH = os.path.join(PROJECT_ROOT, "results", "evaluation_results_our_model.csv")
HUMAN_EVAL_PATH = os.path.join(PROJECT_ROOT, "results", "human_evaluation_data_for_our_model.csv")

# ==============================================================================
# 2. æ¨¡å‹åŠ è½½ä¸ç”Ÿæˆå‡½æ•°
# ==============================================================================

def load_your_bart_model(base_path, weights_path):
    """ä¸“é—¨åŠ è½½æˆ‘ä»¬å¾®è°ƒå¥½çš„BARTå­¦ç”Ÿæ¨¡å‹"""
    print(f"--- æ­£åœ¨åŠ è½½ä½ å¾®è°ƒå¥½çš„BARTæ¨¡å‹ (GenRec-E) ---")
    print(f"  - åŸºç¡€ç»“æ„: {base_path}")
    print(f"  - å¾®è°ƒæƒé‡: {weights_path}")
    try:
        tokenizer = AutoTokenizer.from_pretrained(base_path, local_files_only=True)
        model = AutoModelForSeq2SeqLM.from_pretrained(base_path, local_files_only=True)
        model.load_state_dict(torch.load(weights_path, map_location=DEVICE), strict=False)
        model = model.to(DEVICE)
        model.eval()
        print("ä½ çš„æ¨¡å‹(GenRec-E)åŠ è½½æˆåŠŸã€‚")
        return model, tokenizer
    except Exception as e:
        print(f"!!! åŠ è½½ä½ çš„æ¨¡å‹å¤±è´¥! è¯·ç¡®ä¿è·¯å¾„æ­£ç¡®ä¸”è®­ç»ƒå·²å®Œæˆã€‚"); print(f"é”™è¯¯: {e}"); return None, None

def generate_explanation(model, tokenizer, history, item):
    """ä¸ºæ¨¡å‹ç”Ÿæˆè§£é‡Š"""
    prompt = f"Instruction: Generate a personalized explanation for the given recommendation.\nInput: User History: {history}\nRecommended Item: {item}"
    inputs = tokenizer(prompt, return_tensors="pt", max_length=512, truncation=True).to(model.device)
    outputs = model.generate(**inputs, max_new_tokens=150, num_beams=5)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# ==============================================================================
# 3. ä¸»ç¨‹åº (MAIN LOGIC)
# ==============================================================================

def main():
    your_model, your_tokenizer = load_your_bart_model(YOUR_MODEL_BASE_PATH, YOUR_MODEL_WEIGHTS_PATH)
    if not your_model: 
        return
        
    print("\n--- æ­£åœ¨ä»æœ¬åœ°åŠ è½½è¯„ä¼°æŒ‡æ ‡ ---")
    try:
        rouge = evaluate.load(ROUGE_SCRIPT_PATH)
        print("ROUGEè¯„ä¼°æŒ‡æ ‡åŠ è½½æˆåŠŸã€‚")
    except Exception as e:
        print(f"!!! åŠ è½½ROUGEå¤±è´¥: {e}"); return

    # --- ã€æ ¸å¿ƒä¿®å¤ã€‘æˆ‘ä»¬åœ¨è¿™é‡Œï¼Œæ‰‹åŠ¨åœ°ã€å®Œå…¨ç¦»çº¿åœ°åˆå§‹åŒ–BERTScorer ---
    print("æ­£åœ¨åˆå§‹åŒ–BERTScorer (å°†ä»æœ¬åœ°åŠ è½½roberta-large)...")
    try:
        # 1. æˆ‘ä»¬è‡ªå·±åˆ›å»ºBERTScorerå®ä¾‹ï¼Œå¹¶æ˜ç¡®æŒ‡å®šroberta-largeçš„æœ¬åœ°è·¯å¾„
        scorer = BERTScorer(model_type=ROBERTA_LOCAL_PATH, lang="en", rescale_with_baseline=True, device=DEVICE)
        print("BERTScoreråˆå§‹åŒ–æˆåŠŸã€‚")
    except Exception as e:
        print(f"!!! åˆå§‹åŒ–BERTScorerå¤±è´¥ï¼Œè¯·æ£€æŸ¥roberta-largeæ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´: {e}"); return
    
    print(f"\n--- æ­£åœ¨åŠ è½½æµ‹è¯•æ•°æ® ---")
    try:
        df = pd.read_csv(TEST_DATA_PATH)
        # ä¸ºäº†å¿«é€Ÿæµ‹è¯•ï¼Œå…ˆåªè¯„ä¼°100æ¡ã€‚æ­£å¼è¯„ä¼°æ—¶è¯·æ³¨é‡Šæ‰ä¸‹é¢è¿™è¡Œ
        df = df.head(10)
    except FileNotFoundError:
        print(f"!!! é”™è¯¯: æµ‹è¯•é›†æ–‡ä»¶æœªæ‰¾åˆ°! '{TEST_DATA_PATH}'"); return

    results = []
    print(f"\n--- æ­£åœ¨ä¸ºä½ çš„æ¨¡å‹ (GenRec-E) ç”Ÿæˆ {len(df)} æ¡è§£é‡Š ---")
    for index, row in tqdm(df.iterrows(), total=len(df)):
        history, item, reference = str(row['history']), str(row['recommended_item']), str(row['explanation'])
        your_pred = generate_explanation(your_model, your_tokenizer, history, item)
        results.append({ 
            'history': history, 'item': item,
            'golden': reference, 'prediction': your_pred
        })
        
    results_df = pd.DataFrame(results)
    references = results_df['golden'].tolist()
    predictions = results_df['prediction'].tolist()
    
    print("\n--- æ­£åœ¨è®¡ç®—è‡ªåŠ¨åŒ–è¯„ä¼°æŒ‡æ ‡ ---")
    print("æ­£åœ¨è®¡ç®—ROUGE...")
    rouge_scores = rouge.compute(predictions=predictions, references=references)
    
    print("æ­£åœ¨è®¡ç®—BERTScore...")
    # 2. æˆ‘ä»¬ç”¨è‡ªå·±åˆ›å»ºçš„scoreræ¥è®¡ç®—åˆ†æ•°
    (P, R, F1) = scorer.score(predictions, references, verbose=False) # å°†verboseè®¾ä¸ºFalseï¼Œé¿å…è¿‡å¤šæ‰“å°
    bert_f1 = F1.mean().item()

    print("\n--- ä½ çš„æ¨¡å‹ (GenRec-E) è¯„ä¼°ç»“æœ ---")
    print(f"{'Metric':<15} | {'Score':<10}")
    print("-" * 30)
    print(f"{'ROUGE-1':<15} | {rouge_scores.get('rouge1', 0.0):.4f}")
    print(f"{'ROUGE-2':<15} | {rouge_scores.get('rouge2', 0.0):.4f}")
    print(f"{'ROUGE-L':<15} | {rouge_scores.get('rougeL', 0.0):.4f}")
    print(f"{'BERTScore-F1':<15} | {bert_f1:.4f}")
    
    results_df.to_csv(RESULTS_PATH, index=False)
    results_df.to_csv(HUMAN_EVAL_PATH, index=False)
    print(f"\nè¯¦ç»†ç”Ÿæˆç»“æœå·²ä¿å­˜åˆ°: {RESULTS_PATH}")
    print("\nğŸ‰ ä½ çš„æ¨¡å‹è¯„ä¼°å®Œæˆï¼")

if __name__ == "__main__":
    main()